# ðŸ—ï¸ Arquitectura Integral de Datos para COVALTO  
### **Por: Alejandra HincapiÃ© GarzÃ³n**  
**Gerente de IngenierÃ­a de Datos e IA â€” Liderazgo tÃ©cnico, estratÃ©gico y sistÃ©mico**

---

## ðŸŒ Modelo en Capas y AgnÃ³stico de Nube

Esta arquitectura estÃ¡ diseÃ±ada **en capas**, lo que permite:

- Separar responsabilidades: ingestiÃ³n, limpieza, semÃ¡ntica y productos de datos.  
- Facilitar mantenibilidad, escalabilidad y adopciÃ³n de nuevas tecnologÃ­as sin romper procesos existentes.  
- Aislar cambios: se pueden mejorar capas individuales sin afectar al resto.  

AdemÃ¡s, es **agnÃ³stica de nube**, lo que significa que **puede implementarse en AWS, GCP, Azure o entornos hÃ­bridos**, usando servicios equivalentes segÃºn disponibilidad y costos.

---

## ðŸŽ¯ PropÃ³sito de esta Propuesta

DiseÃ±ar una **arquitectura moderna, escalable y segura** que permita a COVALTO habilitar:

- AutonomÃ­a para que los equipos de negocio puedan analizar sus datos  
- CreaciÃ³n de caracterÃ­sticas robustas para modelos de riesgo  
- Ingesta y monitoreo en tiempo real de eventos de fraude  
- Gobernanza, calidad y trazabilidad exigidas en un banco regulado  

Esta soluciÃ³n integra simultÃ¡neamente **necesidades de negocio**, **restricciones operativas**, y **madurez tÃ©cnica**, ofreciendo una visiÃ³n completa del ecosistema de datos.

---

# ðŸ§© 1. Resumen de los Casos de Uso

### **1ï¸âƒ£ VisualizaciÃ³n del Comportamiento del Cliente**
**Dolores actuales:**  
- Solicitudes ad-hoc que generan retrasos â†’ **SoluciÃ³n:** self-service BI con datos normalizados.  
- Diferencias de significado entre fuentes â†’ **SoluciÃ³n:** modelo semÃ¡ntico Ãºnico.  
- Datos dispersos en mÃºltiples sistemas â†’ **SoluciÃ³n:** ingesta unificada y catÃ¡logo de datos.  
- Ausencia de un modelo de datos comÃºn â†’ **SoluciÃ³n:** diccionario de datos y modelo empresarial.  

---

### **2ï¸âƒ£ EvaluaciÃ³n de Riesgo para Hipotecas**
**Dolores actuales:**  
- Modelos dependientes de datos crudos â†’ **SoluciÃ³n:** Feature Store con caracterÃ­sticas versionadas.  
- Procesos no repetibles â†’ **SoluciÃ³n:** pipelines reproducibles batch y streaming.  
- Falta de trazabilidad â†’ **SoluciÃ³n:** linaje completo y auditorÃ­a automÃ¡tica.  

---

### **3ï¸âƒ£ Monitoreo de Fraude en Tiempo Real**
**Dolores actuales:**  
- Latencia alta y accesos inconsistentes â†’ **SoluciÃ³n:** ingestiÃ³n streaming con baja latencia y acceso unificado.  
- Procesamiento poco confiable â†’ **SoluciÃ³n:** arquitectura basada en eventos con alertas automÃ¡ticas.  
- Acceso fragmentado a caracterÃ­sticas â†’ **SoluciÃ³n:** Feature Store accesible desde tiempo real y batch.  

---

# ðŸ›ï¸ 2. Principios de DiseÃ±o

- **Datos como Producto:** responsable, documentaciÃ³n, SLA y contratos claros.  
- **SemÃ¡ntica compartida:** diccionario y modelo comÃºn.  
- **Arquitectura en capas:** responsabilidades separadas y mantenibles.  
- **Procesamiento batch y en tiempo real:** estrategia segÃºn necesidad.  
- **Trazabilidad y gobernanza desde el diseÃ±o:** datos auditables y rastreables.  
- **Escalabilidad horizontal:** manejo eficiente de APIs y paralelismo.  
- **Calidad de datos:** validaciones automÃ¡ticas, alertas y mÃ©tricas de desempeÃ±o.  

---

# ðŸ—ï¸ 3. Arquitectura Propuesta (VisiÃ³n 360Â°)

## ðŸ¥‡ **Capa 0 â€” Ingesta Unificada (Batch + Streaming + CDC)**

| Fuente                                           | Tipo                           | Acceso                                            | Estrategia                                                                     |
| ------------------------------------------------ | ------------------------------ | ------------------------------------------------- | ------------------------------------------------------------------------------ |
| Declaraciones de Impuestos Anuales               | API XML                        | Token + autorizaciÃ³n digital                      | IngestiÃ³n batch, control de lÃ­mites, procesamiento ETL a Data Lake raw         |
| Historial de Transacciones de Tarjeta de CrÃ©dito | API JSON / PostgreSQL interno  | API: token, bulk & streaming; DB: baja integridad | Pipelines streaming desde API; ETL para DBs internas con limpieza y validaciÃ³n |
| Extractos Bancarios                              | API XML / S3 (PDFs e imÃ¡genes) | API: token + firma; S3: no estructurado           | ETL batch/streaming para XML; OCR y ML para PDFs e imÃ¡genes                    |

**Notas adicionales:**

- Declaraciones de Impuestos: colas de trabajo para paralelizar llamadas sin exceder lÃ­mites.  
- Transacciones de Tarjeta: captura de cambios (CDC) para mantener datos actualizados; validaciÃ³n de integridad y consistencia.  
- Extractos Bancarios: XML â†’ parseo estructurado; PDFs/ImÃ¡genes â†’ OCR + NLP para extracciÃ³n; validaciones de completitud y consistencia.  

**TecnologÃ­as sugeridas:** Kafka / PubSub, Airflow / Databricks Jobs, S3 / GCS con Parquet / Delta, OCR (AWS Textract / GCP Document AI), Spark / Beam, Debezium / Fivetran  

---

## ðŸ¥ˆ **Capa 1 â€” NormalizaciÃ³n y Limpieza de Datos**

Objetivo: **eliminar ambigÃ¼edad y unificar la semÃ¡ntica de todos los datos**.

Incluye:

- TipificaciÃ³n de datos  
- EstandarizaciÃ³n de fechas, valores monetarios e identificadores  
- DetecciÃ³n de duplicados  
- ValidaciÃ³n contra reglas de negocio  
- AuditorÃ­a y linaje automÃ¡tico  
- Validaciones de calidad: completitud, consistencia, patrones de datos y alertas  

ðŸ“Œ **Resultado:** Tablas limpias y consistentes, listas para anÃ¡lisis.

---

## ðŸ¥‰ **Capa 2 â€” Modelo SemÃ¡ntico Empresarial**

CreaciÃ³n de modelos con significados Ãºnicos:

- Cliente  
- Cuenta  
- TransacciÃ³n  
- Comportamiento de crÃ©dito  
- MÃ©tricas financieras derivadas  

**Beneficios:**  
- Elimina confusiones semÃ¡nticas  
- Facilita el anÃ¡lisis por parte de negocio  
- Aporta entendimiento estÃ¡ndar a riesgo y fraude  
- Mantiene los datos actualizados mediante captura de cambios (CDC)

---

## ðŸ… **Capa 3 â€” Productos de Datos segÃºn Caso de Uso**

### **A. VisualizaciÃ³n y BI del Cliente**
- ExposiciÃ³n de datos normalizados y validados  
- Diccionario de datos actualizado  
- Acceso controlado segÃºn permisos  
- Alertas automÃ¡ticas si los datos pierden consistencia  

ðŸŽ¯ Analistas pueden crear reportes sin depender de ingenierÃ­a.

---

### **B. Feature Store para Modelos de Riesgo**
- Almacenamiento de caracterÃ­sticas con versionamiento  
- Tiempo de validez de cada caracterÃ­stica  
- Procesamiento batch y en streaming sincronizado  
- Validaciones de calidad y consistencia de los datos  

ðŸŽ¯ Garantiza reproducibilidad, equidad y precisiÃ³n en los modelos de riesgo.

---

### **C. Monitoreo de Fraude en Tiempo Real**
- Transformaciones y enriquecimiento de datos en tiempo real  
- CÃ¡lculo de puntuaciones de riesgo en lÃ­nea  
- Almacenamiento temporal para colas de eventos  
- DetecciÃ³n de patrones mediante reglas y modelos predictivos  
- Alertas automÃ¡ticas ante inconsistencias o retrasos  

ðŸŽ¯ Velocidad y precisiÃ³n para proteger la operaciÃ³n bancaria.

---

# ðŸ›¡ï¸ 4. Gobernanza, Calidad y Confianza

- CatÃ¡logo y diccionario de datos  
- GestiÃ³n de acceso basada en roles y cumplimiento regulatorio  
- Contratos de datos entre equipos  
- Monitoreo de procesos con mÃ©tricas y alertas  
- Validaciones automÃ¡ticas de calidad  
- Linaje completo desde origen hasta consumo  

ðŸŽ¯ **Beneficio:** datos confiables y rastreables para BI, riesgo y fraude.

---

# ðŸ§  5. Diagrama de Arquitectura

flowchart LR
    %% Columnas como subgraphs para organizaciÃ³n visual

    subgraph S1["Fuentes de Datos"]
        direction TB
        A[Declaraciones Anuales XML]
        B[Transacciones de Tarjetas JSON]
        C[Bases de Datos Internas]
        D[Extractos Bancarios XML]
        E[PDFs e ImÃ¡genes en S3]
    end

    subgraph S2["Capa 0 - Ingesta y CDC"]
        direction TB
        I1[RegulaciÃ³n + Colas de Trabajo]
        I2[Ingesta en Streaming + Captura de Cambios]
        I3[ExtracciÃ³n Batch + Reglas de Calidad + Captura de Cambios]
        I4[Parseo XML]
        I5[OCR y ExtracciÃ³n NLP]
    end

    subgraph S3["Capa 1 - Limpieza y NormalizaciÃ³n"]
        direction TB
        C1[NormalizaciÃ³n + ValidaciÃ³n de Calidad]
    end

    subgraph S4["Capa 2 - Modelo SemÃ¡ntico"]
        direction TB
        S1c[Cliente]
        S2c[Cuenta]
        S3c[TransacciÃ³n]
        S4c[MÃ©tricas Financieras]
    end

    subgraph S5["Capa 3 - Productos de Datos"]
        direction LR
        subgraph P1["VisualizaciÃ³n y BI"]
            direction TB
            P1a[VisualizaciÃ³n y BI]
        end
        subgraph P2["Motor de Fraude"]
            direction TB
            P2a[Motor de Fraude en Tiempo Real]
        end
        subgraph P3["Feature Store"]
            direction TB
            P3a[Feature Store para Riesgo]
        end
    end

    %% Conexiones Fuentes -> Ingesta
    A --> I1
    B --> I2
    C --> I3
    D --> I4
    E --> I5

    %% Ingesta -> Limpieza
    I1 --> C1
    I2 --> C1
    I3 --> C1
    I4 --> C1
    I5 --> C1

    %% Limpieza -> Modelo SemÃ¡ntico
    C1 --> S1c
    C1 --> S2c
    C1 --> S3c
    C1 --> S4c

    %% Modelo SemÃ¡ntico -> Productos de Datos
    S1c --> P1a
    S3c --> P2a
    S4c --> P3a
    S2c -.-> P3a  %% Cuenta conectada opcionalmente al Feature Store



