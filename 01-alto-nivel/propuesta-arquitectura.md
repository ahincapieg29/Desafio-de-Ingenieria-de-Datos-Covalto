# ðŸ—ï¸ Arquitectura Integral de Datos para COVALTO  
### **Por: Alejandra HincapiÃ© GarzÃ³n**  
**Gerente de IngenierÃ­a de Datos e IA â€” Liderazgo tÃ©cnico, estratÃ©gico y sistÃ©mico**

---

## ðŸŒ Modelo en Capas y AgnÃ³stico de Nube

Esta arquitectura estÃ¡ diseÃ±ada **en capas**, lo que permite:

- Separar responsabilidades: ingestiÃ³n, limpieza, semÃ¡ntica y productos de datos.  
- Facilitar mantenibilidad, escalabilidad y adopciÃ³n de nuevas tecnologÃ­as sin romper procesos existentes.  
- Aislar cambios: se pueden mejorar capas individuales sin afectar al resto.  

AdemÃ¡s, es **agnÃ³stica de nube**, lo que significa que **puede implementarse en AWS, GCP, Azure o entornos hÃ­bridos**, usando servicios equivalentes segÃºn disponibilidad y costos.

---

## ðŸŽ¯ PropÃ³sito de esta Propuesta

DiseÃ±ar una **arquitectura moderna, escalable y segura** que permita a COVALTO habilitar:

- AutonomÃ­a para que los equipos de negocio puedan analizar sus datos  
- CreaciÃ³n de caracterÃ­sticas robustas para modelos de riesgo  
- Ingesta y monitoreo en tiempo real de eventos de fraude  
- Gobernanza, calidad y trazabilidad exigidas en un banco regulado  

Esta soluciÃ³n integra simultÃ¡neamente **necesidades de negocio**, **restricciones operativas**, y **madurez tÃ©cnica**, ofreciendo una visiÃ³n completa del ecosistema de datos.

---

# ðŸ§© 1. Resumen de los Casos de Uso

### **1ï¸âƒ£ VisualizaciÃ³n del Comportamiento del Cliente**
**Dolores actuales:**  
- Solicitudes ad-hoc que generan retrasos â†’ **SoluciÃ³n:** Self-service BI con datos normalizados.  
- Diferencias de significado entre fuentes â†’ **SoluciÃ³n:** Modelo semÃ¡ntico Ãºnico.  
- Datos dispersos en mÃºltiples sistemas â†’ **SoluciÃ³n:** Ingesta unificada y catÃ¡logo de datos.  
- Ausencia de un modelo de datos comÃºn â†’ **SoluciÃ³n:** Diccionario de datos y modelo empresarial.  

---

### **2ï¸âƒ£ EvaluaciÃ³n de Riesgo para Hipotecas**
**Dolores actuales:**  
- Modelos dependientes de datos crudos â†’ **SoluciÃ³n:** Feature Store con caracterÃ­sticas versionadas.  
- Procesos no repetibles â†’ **SoluciÃ³n:** Pipelines reproducibles batch y streaming.  
- Falta de trazabilidad â†’ **SoluciÃ³n:** Linaje completo y auditorÃ­a automÃ¡tica.  

---

### **3ï¸âƒ£ Monitoreo de Fraude en Tiempo Real**
**Dolores actuales:**  
- Latencia alta y accesos inconsistentes â†’ **SoluciÃ³n:** IngestiÃ³n streaming con baja latencia y acceso unificado.  
- Procesamiento poco confiable â†’ **SoluciÃ³n:** Arquitectura basada en eventos con alertas automÃ¡ticas.  
- Acceso fragmentado a caracterÃ­sticas â†’ **SoluciÃ³n:** Feature Store accesible desde tiempo real y batch.  

---

# ðŸ›ï¸ 2. Principios de DiseÃ±o

- **Datos como Producto:** responsable, documentaciÃ³n, SLA y contratos claros.  
- **SemÃ¡ntica compartida:** diccionario y modelo comÃºn.  
- **Arquitectura en capas:** responsabilidades separadas y mantenibles.  
- **Procesamiento batch y en tiempo real:** estrategia segÃºn necesidad.  
- **Trazabilidad y gobernanza desde el diseÃ±o:** datos auditables y rastreables.  
- **Escalabilidad horizontal:** manejo eficiente de APIs y paralelismo.  
- **Calidad de datos:** validaciones automÃ¡ticas, alertas y mÃ©tricas de desempeÃ±o.  

---

# ðŸ—ï¸ 3. Arquitectura Propuesta (VisiÃ³n 360Â°)

## ðŸ¥‡ **Capa 0 â€” Ingesta Unificada (Batch + Streaming + CDC)**

| Fuente                                           | Tipo                           | Acceso                                            | Estrategia                                                                     |
| ------------------------------------------------ | ------------------------------ | ------------------------------------------------- | ------------------------------------------------------------------------------ |
| Declaraciones de Impuestos Anuales               | API XML                        | Token + autorizaciÃ³n digital                      | IngestiÃ³n batch, control de lÃ­mites, procesamiento ETL a Data Lake raw         |
| Historial de Transacciones de Tarjeta de CrÃ©dito | API JSON / PostgreSQL interno  | API: token, bulk & streaming; DB: baja integridad | Pipelines streaming desde API; ETL para DBs internas con limpieza y validaciÃ³n |
| Extractos Bancarios                              | API XML / S3 (PDFs e imÃ¡genes) | API: token + firma; S3: no estructurado           | ETL batch/streaming para XML; OCR y ML para PDFs e imÃ¡genes                    |

**Notas adicionales:**

- Declaraciones de Impuestos: colas de trabajo para paralelizar llamadas sin exceder lÃ­mites.  
- Transacciones de Tarjeta: captura de cambios (CDC) para mantener datos actualizados; validaciÃ³n de integridad y consistencia.  
- Extractos Bancarios: XML â†’ parseo estructurado; PDFs/ImÃ¡genes â†’ OCR + NLP para extracciÃ³n; validaciones de completitud y consistencia.  

**TecnologÃ­as sugeridas:** Kafka / PubSub, Airflow / Databricks Jobs, S3 / GCS con Parquet / Delta, OCR (AWS Textract / GCP Document AI), Spark / Beam, Debezium / Fivetran  

---

## ðŸ¥ˆ **Capa 1 â€” NormalizaciÃ³n y Limpieza de Datos**

Objetivo: **eliminar ambigÃ¼edad y unificar la semÃ¡ntica de todos los datos**.

Incluye:

- TipificaciÃ³n de datos  
- EstandarizaciÃ³n de fechas, valores monetarios e identificadores  
- DetecciÃ³n de duplicados  
- ValidaciÃ³n contra reglas de negocio  
- AuditorÃ­a y linaje automÃ¡tico  
- Validaciones de calidad: completitud, consistencia, patrones de datos y alertas  

ðŸ“Œ **Resultado:** Tablas limpias y consistentes, listas para anÃ¡lisis.

---

## ðŸ¥‰ **Capa 2 â€” Modelo SemÃ¡ntico Empresarial**

| Entidad      | DescripciÃ³n                                                   |
| ------------ | ------------------------------------------------------------- |
| Cliente      | InformaciÃ³n Ãºnica del cliente: perfil, segmentaciÃ³n y comportamiento |
| Cuenta       | Detalles de cuentas financieras y relaciones con el cliente   |
| TransacciÃ³n  | Registros de movimientos y pagos                               |
| Comportamiento de crÃ©dito | MÃ©tricas derivadas de riesgo y cumplimiento de pagos |
| MÃ©tricas financieras derivadas | Indicadores de negocio y agregaciones financieras |

**Beneficios:**  
- Elimina confusiones semÃ¡nticas  
- Facilita el anÃ¡lisis de negocio  
- Garantiza consistencia en riesgo y fraude  
- Mantiene datos actualizados mediante CDC  

---

## ðŸ… **Capa 3 â€” Productos de Datos segÃºn Caso de Uso**

### **A. VisualizaciÃ³n y BI del Cliente**
- ExposiciÃ³n de datos normalizados y validados  
- Diccionario de datos actualizado  
- Acceso controlado segÃºn permisos  
- Alertas automÃ¡ticas si los datos pierden consistencia  

ðŸŽ¯ Analistas pueden crear reportes sin depender de ingenierÃ­a.

---

### **B. Feature Store para Modelos de Riesgo**
- Almacenamiento de caracterÃ­sticas con versionamiento  
- Tiempo de validez de cada caracterÃ­stica  
- Procesamiento batch y en streaming sincronizado  
- Validaciones de calidad y consistencia de los datos  

ðŸŽ¯ Garantiza reproducibilidad, equidad y precisiÃ³n en los modelos de riesgo.

---

### **C. Monitoreo de Fraude en Tiempo Real**
- Transformaciones y enriquecimiento de datos en tiempo real  
- CÃ¡lculo de puntuaciones de riesgo en lÃ­nea  
- Almacenamiento temporal para colas de eventos  
- DetecciÃ³n de patrones mediante reglas y modelos predictivos  
- Alertas automÃ¡ticas ante inconsistencias o retrasos  

ðŸŽ¯ Velocidad y precisiÃ³n para proteger la operaciÃ³n bancaria.

---

# ðŸ›¡ï¸ 4. Gobernanza, Calidad y Confianza

- CatÃ¡logo y diccionario de datos  
- GestiÃ³n de acceso basada en roles y cumplimiento regulatorio  
- Contratos de datos entre equipos  
- Monitoreo de procesos con mÃ©tricas y alertas  
- Validaciones automÃ¡ticas de calidad  
- Linaje completo desde origen hasta consumo
-  **AlfabetizaciÃ³n y cultura de datos:** equipos entrenados en buenas prÃ¡cticas y significado de datos  

ðŸŽ¯ **Beneficio:** datos confiables, rastreables y usados de forma correcta por toda la organizaciÃ³n. 

---

# ðŸ§  5. Diagrama de Arquitectura

```mermaid
flowchart LR

%% ==================== Fuentes ====================
subgraph Sources["ðŸ”¹ Fuentes de Datos"]
    A[Declaraciones Anuales XML]
    B[Transacciones de Tarjetas JSON]
    C[Bases de Datos Internas]
    D[Estados de Cuenta XML]
    E[PDFs e ImÃ¡genes en S3]
end

%% ==================== Capa 0 - Ingesta ====================
subgraph Ingestion["ðŸŸ¦ Capa 0 - Ingesta y CDC"]
    A --> I1[RegulaciÃ³n + Colas de Trabajo]
    B --> I2[Ingesta en Streaming + CDC]
    C --> I3[ExtracciÃ³n Batch + Calidad + CDC]
    D --> I4[Parseo XML]
    E --> I5[OCR + NLP]
end

%% ==================== Capa 1 - Limpieza ====================
subgraph Processing["ðŸŸ© Capa 1 - Limpieza y NormalizaciÃ³n"]
    I1 --> C1[NormalizaciÃ³n + ValidaciÃ³n]
    I2 --> C1
    I3 --> C1
    I4 --> C1
    I5 --> C1
end

%% ==================== Capa 2 - Modelo SemÃ¡ntico ====================
subgraph Semantic["ðŸŸ¨ Capa 2 - Modelo"]
    C1 --> S1[Cliente]
    C1 --> S2[Cuenta]
    C1 --> S3[TransacciÃ³n]
    C1 --> S4[CrÃ©dito]
    C1 --> S5[KPI Finanzas]
end

%% ==================== Capa 3 - Productos de Datos ====================
subgraph Products["ðŸŸ§ Capa 3 - Productos"]
    S1 --> BI[VisualizaciÃ³n / BI]
    S3 --> FR[Fraude Tiempo Real]
    S4 --> FS[Feature Store]
end
